-**NumberofMergedQRegions:**Thisisgenerallydeterminedbythedesiredalgorithmcomplexity.Forscenarioswithlowalgorithmcomplexityrequirements,asizeoftop-k/4canbechosen.Ifalgorithmcomplexityisaconcern,itcanbeflexiblyset.Forexample,inthefirststep,thesegmentsizeisfixedat32,thenumberofhighlycorrelatedregionsissetto$\frac{n^{\frac{1}{2}}}{32}$,andthenumberofmergedregionsisalso$\frac{n^{\frac{1}{2}}}{32}$,resultinginafinalalgorithmcomplexityof$O(n^{\frac{3}{2}})$.FullymergingisequivalenttotheoriginalAttention,withacomplexityof$O(n^{2})$.
|Model|TREC|TriviaQA|SAMSum|LCC|RepoBench-P|
|-|-|-|-|-|-|
|GPT-3.5-Turbo-16k|68|**91.4**|**41.7**|54.7|53.6|
|LongChat-v1.5-7B-32k|63.5|82.3|34.2|53|**55.3**|
|XGen-7B-8k|65.5|77.8|25.3|38.6|38.6|
|InternLM-7B-8k|52|77.8|21.2|44.1|28.8|
|ChatGLM2-6B-32k|62.5|78.7|36.3|55.6|49.9|
|Vicuna-v1.5-7B-16k|71.5|86.2|40.8|51|43.5|
|ChatGLM3-6B-32k|**79**|87.1|38.2|57.66|54.76|
|**Llama2-7B-chat-4k**|61.5|77.8|40.7|52.4|43.8|
|**Llama-7B-32k-Selection&Merging-PI**|72.6|85.7|40.6|**61.95**|49.09|

|Model|TREC|TriviaQA|SAMSum|LCC|RepoBench-P|
|-|-|-|-|-|-|
|GPT-3.5-Turbo-16k|68|**91.4**|**41.7**|54.7|53.6|
|**Llama2-7B-chat-4k**|61.5|77.8|40.7|52.4|43.8|
|LongChat-v1.5-7B-32k|63.5|82.3|34.2|53|**55.3**|
|XGen-7B-8k|65.5|77.8|25.3|38.6|38.6|
|InternLM-7B-8k|52|77.8|21.2|44.1|28.8|
|ChatGLM2-6B-32k|62.5|78.7|36.3|55.6|49.9|
|Vicuna-v1.5-7B-16k|71.5|86.2|40.8|51|43.5|
|ChatGLM3-6B-32k|**79**|87.1|38.2|57.66|54.76|
|**Llama-7B-32k-Selection&Merging**|72.6|85.7|40.6|**61.95**|49.09|

|Model|PPL(PG19)|Model|ImageNetAccuracy(%)|
|-|-|-|-|
|TransformerXL|36.3|VVT-T-12.9M|79.4|
|RoutingTransformer|33.3|SwinTransformer-29M|81.3|
|LandmarkAttention-200M|14.55|Biformer-13.1M|81.4|
|Selection-MergingAttention-200M|10.9|Selection-MergingAttention-13.1M|82.1|


|Length|2K|4K|8K|16K|32K|64K|
|-|-|-|-|-|-|-|
|Llama-7B-32K-Selection-Merging|2.3|2.4|2.5|2.6|2.5|2.4|

**Table:**EvaluationonProofPile

||2K|4K|8K|16K|32K|
|-|-|-|-|-|-|
|**Llama-7B-MS-no_LoRA**|7.06|6.96|6.78|6.56|6.93|
|**Llama-7B-MS-LoRA**|7.61|7.42|7.17|7.03|7.06|

**Table:**EvaluationMetrics

|Configuration|Memory(MB)|Time(s/it)|
|-|-|-|
|WithDeepSpeed&LoRA|36,786|6.37|
|WithoutDeepSpeed|31,524|6.19|
|WithoutLoRA|35,074|7.28|
|WithoutDeepSpeed&LoRA|40,132|6.38|

**Table:**MemoryandTimeComparison


|Model|PPL(PG19)|Model|ImageNetAccuracy(%)|
|-|-|-|-|
|TransformerXL|36.3|VVT-T-12.9M|79.4|
|RoutingTransformer|33.3|SwinTransformer-29M|81.3|
|LandmarkAttention-200M|14.55|Biformer-13.1M|81.4|
|Selection-MergingAttention-200M|10.9|Selection-MergingAttention-13.1M|82.1|

|PPL(PG19)|1×8192|FlashAttention/w.o|
|-|-|-|
|MSAttention-60M|15.9|-|
|MSAttention-202M|10.9|19,888/22,096|
|LandmarkAttention-202M|14.55|>40,960(OOM)|

|Model|FLOPs(G)|Params(M)|Top-1Acc.(%)|
|-|-|-|-|
|Swin-T|4.5|29|81.3|
|BiFormer-T|2.2|13.1|81.4|
|MSAttention(Ours)|2.0|13.1|**82.0**|

|Passkey|2K|4K|8K|16K|32K|40K|56K|64K|80K|100K|128K|160K|200K|
|-|-|-|-|-|-|-|-|-|-|-|-|-|-|
|Llama-7B-32K-Selection-Merging-NTK|1.0|1.0|1.0|1.0|1.0|0.9|0.9|0.9|0.8/0.9|0.7/0.9|0.6/0.9|-/0.9|-/0.9|

*Table:PerformanceonPasskeyTask*

|Model|PPL(PG19)|TrainingMemoryUsage(MB)|
|-||-|
|MSAttention-60M|15.9|20,886|
|MSAttention-202M(Landmarkconfig)|10.9|37,624|
|LandmarkAttention-202M|14.55|>40,960(OOM)|

*Table:PerformanceandMemoryComparison*

|Model|PPL(PG19)|TrainingMemoryUsage(MB)|2×8192|1×8192|FlashAttention/w.o|1×4096|1×2048|
|-|-|-|-|-|-|-||
|MSAttention-60M|15.9|20,886|-|-|-|-|-|
|MSAttention-202M(Landmarkconfig)|10.9|37,624|19,888/22,096|12,774/13,872|9,562/9,716|-|-|
|LandmarkAttention-202M|14.55|>40,960(OOM)|>40,960(OOM)|>40,960(OOM)|>40,960(OOM)|17,938|-|

*Table:PerformanceandMemoryComparison*

|Configuration|withDeepSpeed&LoRA|withoutDeepSpeed|withoutLoRA|withoutDeepSpeed&LoRA|
|-|-|-|-|-|
|Llama7B-MS-16K|36,786MB|6.07s/it|31,524MB|6.19s/it|OOM|40,132MB|6.38s/it|
|Llama7B-MS-16K(overrideTrainer)|34,404MB|6.37s/it|35,074MB|7.28s/it|-|-|

*Table:MemoryUsageComparison*

|TrainingLength|2k-8k|8k-16k|32k|36k|40k|48k|64k|72k|80k|100k|
|-|-||-|-|-|-|-|-|-|-|
|MS-16K|1.0|1.0|0.9|0.4/0.8|0.2/0.8|0.2/0.7|0.0/0.6|0.0|0.0|0.0|
|MS-32K|1.0|1.0|1.0|1.0|1.0|1.0|0.9|0.1/0.8|0.1/0.6|0.0/0.5|
|MS-50K|1.0|1.0|1.0|1.0|1.0|1.0|1.0|1.0|1.0|0.9|
|LongLora-32K|1.0|1.0|1.0|0.0/0.7|0.0/0.7|0.0/0.2|0.0|0.0|0.0|0.0|

*Table:PerformanceonPasskeyTaskwithDifferentTrainingLengths*



Dear Reviewers,

Thank you for your valuable feedback. We have updated our experiments and theoretical explanations regarding the positional interpolation method. The results are summarized in the table below:

| **Model**           | **2K-32K** | **40K** | **48K** | **56K** | **64K** | **80K** | **100K** |
|---------------------|------------|---------|---------|---------|---------|---------|----------|
| **Llama7B-MS-16K-32K position random**  | 1.0        | -/1.0   | -/1.0   | -       | -       | -       | -        |
| **Llama7B-MS-16K-64K position random**  | 1.0        | -/1.0   | -/1.0   | -/1.0   | -/1.0   | -/1.0   | -/0.6    |


Based on the reviewers' suggestions and guidance, we have further reflected on our method and demonstrated its potential. Initially, our method was able to extrapolate to twice the training length. Upon analysis, we believe this is due to the following reasons: 

1. Compared to full Attention, which uses positional information from all previous tokens, our selection mechanism allows us to choose an arbitrary number of relevant key-value pairs (KV) to adapt the Attention step to different positional information. This ensures that even when only partial correct positional information is available, the model can still generate accurate tokens.
  
2. When fine-tuning with a length of $l$, the length of correct positional information the model can recognize is $l_1 = l$. The maximum potential achieved by our arbitrary selection mechanism allows for correct autoregression with minimal learned positional information, corresponding to the relative positional shift $l_2$. This shift $l_2 = l$ can be maximized by our selection mechanism during fine-tuning. Therefore, the final extrapolation length is $l_1 + l_2$.

To partially verify our theory, we fine-tuned Llama2-7B with a length of $l = 16K$. In a standard fine-tuning process, the range of Position_ids in the length direction is 1-16K. We introduced an initial position to allow the model to see more positions, thus increasing $l_1$. For example, we selected starting positions within the range of 1-32K at each fine-tuning step, i.e., $l_1 = 32K$. We successfully achieved 100% accuracy in the 48K length passkey task. Similarly, we set $l_1 = 64K$, and with a positional interpolation ratio of $64K/4K = 16$, we achieved 100% accuracy in the 80K length passkey task. Further experiments are ongoing. Based on the above analysis, our method combined with positional interpolation requires only short-length fine-tuning to achieve long-length extrapolation, potentially even extending to infinite lengths.



| **Model**           | **2K-32K** | **40K-80K** | **100K** | **128K** | **160K** | **200K** | **220K** | **240K** | **256K** |
|---------------------|------------|-------------|----------|----------|----------|----------|----------|----------|----------|
| **Llama7B-MS-16K-NTK**  | 1.0        | 1.0         | 1.0      | 1.0      | 0.8/1.0  | -/1.0    | -/1.0    | -/0.8    | -/0.7    |


Here’s the content translated into English in a rebuttal style suitable for top-tier conferences like NIPS or ICLR:

---

**Dear Reviewer,**

Thank you for your feedback. However, I believe your assessment is quite one-sided, and I would like to provide the following clarifications:

1. **Extending Sequence Length with MS+NTK-aware Method**: 
   In our updated results, we have demonstrated that by using the MS Attention mechanism combined with NTK-aware training, we can extend the sequence length up to 256K tokens by fine-tuning with only 16K tokens. To the best of my knowledge, no other method achieves a nearly 16x extension of the fine-tuning length. If you are aware of a better approach, please share it. If you are referring to NTK-aware fine-tuning with 128K tokens, our method still saves at least 8x the resources (due to the quadratic nature of attention, potentially even more).

   Below is the performance of the Llama7B-MS-16K model:

   | **Model** | **2K-32K** | **40K-80K** | **100K** | **128K** | **160K** | **200K** | **220K** | **240K** | **256K** |
   |-----------|------------|-------------|----------|----------|----------|----------|----------|----------|----------|
   | **Llama7B-MS-16K** | 1.0 | 1.0 | 1.0 | 1.0 | 0.8/1.0 | -/1.0 | -/1.0 | -/0.9 | -/0.7 |

2. **Inclusion of the Mistral Model**:
   While other reviewers raised the issue of including the Mistral model, your initial comments and weaknesses did not address this point, so we did not respond to it earlier. Now, we are presenting results with the Mistral model, which has been fine-tuned on 16K tokens using our method combined with positional interpolation (PI). Fine-tuning with NTK is still ongoing, and we expect to share the results shortly. Without having conducted these experiments, your unexpected criticism might have been discouraging.

   Below are the results for the Mistral-7B-16K-Selection-Merging model:

   | **Sequence Length** | **2K** | **4K** | **8K** | **16K** | **32K** |
   |---------------------|--------|--------|--------|---------|---------|
   | **Mistral-7B-16K-Selection-Merging** | 3.35 | 3.27 | 3.08 | 2.64 | 2.28 |

   For the Mistral-7B-16K-Selection-Merging-PI model:

   | **Sequence Length** | **4K** | **8K** | **12K** | **16K** | **20K** | **28K** | **32K** |
   |---------------------|--------|--------|---------|---------|---------|---------|---------|
   | **Mistral-7B-16K-Selection-Merging-PI** | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 |

3. **Addressing All Your Concerns**:
   We believe we have addressed nearly all of your concerns. If you feel that any issue has not been satisfactorily answered, please let us know, and we will make further improvements. I am confident in our algorithm. If no further concerns are raised, I will consider that you are satisfied with our responses. Thank you for your consideration.

Based on the above rebuttal, the reasoning behind maintaining your original score is no longer valid. Please provide a better justification. Additionally, we kindly ask that you recognize the strengths of our work instead of focusing solely on its shortcomings. While our algorithm is indeed excellent, no method is flawless. Thank you again for your valuable feedback and your time.

MODEL_PATH="Mpath_to_saving_checkpoints16k_scale4096_m64_w16s512_kojobNTK 

   | **Sequence Length** ------------------------------------------| **40K** | **56K** | **72K** | **80K** | **100K** | **28K** | **32K** |
   | **scale_factor** ----------------------------------------------| **64** | **32** | **16** | **8** | **8** | **28K** | **32K** |
   |---------------------------------------------------------------|--------|--------|---------|---------|---------|---------|---------|
   | **Mpath_to_saving_checkpoints16k_scale4096_m64_w16s512_kojobNTK** | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 |

   | **Sequence Length** | **40K** | **56K** | **72K** | **80K** | **100K** | **128K** | **160K** |
   |--|-|--------|---------|---------|---------|---------|---------|
   | **Mpath_to_saving_checkpoints16k_scale4096_m64_w16s512_kojobNTK** | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 |

$$P_c=\begin{bmatrix}
\text{sin }\theta_0 & \text{sin }\theta_0 & \text{sin }\theta_1 & \text{sin }\theta_1 & \dots & \text{sin }\theta_{d/2-1} & \text{sin }\theta_{d/2-1}\\
\text{sin }2\theta_0 & \text{sin }2\theta_0 & \text{sin }2\theta_1 & \text{sin }2\theta_1 & \dots & \text{sin }2\theta_{d/2-1} & \text{sin }2\theta_{d/2-1}\\
\vdots &&&& \vdots \\
\text{sin }m\theta_0 & \text{sin }m\theta_0 & \text{sin }m\theta_1 & \text{sin }m\theta_1 & \dots & \text{sin }m\theta_{d/2-1} & \text{sin }m\theta_{d/2-1}\\
\vdots &&&& \vdots \\
\text{sin }n\theta_0 & \text{sin }n\theta_0 & \text{sin }n\theta_1 & \text{sin }n\theta_1 & \dots & \text{sin }n\theta_{d/2-1} & \text{sin }n\theta_{d/2-1}\\
\end{bmatrix}$$

= (Q_P^\top \times \frac{\partial L}{\partial \text{Scores}}) \odot P_c + ((Q_P^\top \times \frac{\partial L}{\partial \text{Scores}}) \times W_s^T) \odot P_s\\ 